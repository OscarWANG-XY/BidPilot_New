{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>测试初始化<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development settings loaded\n",
      "INSTALLED_APPS: ['django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'rest_framework', 'corsheaders', 'storages', 'apps.authentication', 'apps.files', 'apps.projects', 'apps.doc_analysis', 'apps.chat', 'django_filters', 'drf_spectacular', 'rest_framework_simplejwt.token_blacklist', 'django_celery_results', 'django_celery_beat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-03-03 13:57:01,481 storage default_storage 的类型: COSStorage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings从哪里加载？: config.settings.development\n",
      "项目根目录对么？: C:\\Users\\huiwa\\Documents\\_All_Projects\\BidPilot_new\\backend\n",
      "文件存储settings对么？: apps.files.storage.COSStorage\n",
      "文件default_storage对么？: COSStorage\n",
      "\n",
      "已经安装的应用 Installed Apps 完整了么？:\n",
      "- django.contrib.admin\n",
      "- django.contrib.auth\n",
      "- django.contrib.contenttypes\n",
      "- django.contrib.sessions\n",
      "- django.contrib.messages\n",
      "- django.contrib.staticfiles\n",
      "- rest_framework\n",
      "- corsheaders\n",
      "- storages\n",
      "- apps.authentication\n",
      "- apps.files\n",
      "- apps.projects\n",
      "- apps.doc_analysis\n",
      "- apps.chat\n",
      "- django_filters\n",
      "- drf_spectacular\n",
      "- rest_framework_simplejwt.token_blacklist\n",
      "- django_celery_results\n",
      "- django_celery_beat\n"
     ]
    }
   ],
   "source": [
    "# Django初始化\n",
    "import django_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关模型：get_user_model, Project, FileRecord, DocumentAnalysis, FileProjectLink, ProjectHistory\n",
    "from django.contrib.auth import get_user_model\n",
    "from apps.doc_analysis.models import DocumentAnalysis, InvalidStatusTransition\n",
    "from apps.projects.models import Project\n",
    "from apps.files.models import FileRecord\n",
    "from django.core.files.uploadedfile import SimpleUploadedFile\n",
    "from apps.doc_analysis.steps._01_extract_docx_elements import DocxExtractorStep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户: 18501771516\n",
      "项目: 测试项目1\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "['“3”不是一个有效的UUID']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\fields\\__init__.py:2761\u001b[0m, in \u001b[0;36mUUIDField.to_python\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   2760\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muuid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUUID\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43minput_form\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2762\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\uuid.py:178\u001b[0m, in \u001b[0;36mUUID.__init__\u001b[1;34m(self, hex, bytes, bytes_le, fields, int, version, is_safe)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mhex\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m32\u001b[39m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbadly formed hexadecimal UUID string\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m int_(\u001b[38;5;28mhex\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: badly formed hexadecimal UUID string",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m项目: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject\u001b[38;5;241m.\u001b[39mproject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 获取已存在的文件\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m file_record \u001b[38;5;241m=\u001b[39m \u001b[43mFileRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m文件: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_record\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\manager.py:87\u001b[0m, in \u001b[0;36mBaseManager._get_queryset_methods.<locals>.create_method.<locals>.manager_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(method)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmanager_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_queryset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\query.py:635\u001b[0m, in \u001b[0;36mQuerySet.get\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery\u001b[38;5;241m.\u001b[39mcombinator \u001b[38;5;129;01mand\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m kwargs):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotSupportedError(\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling QuerySet.get(...) with filters after \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m() is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery\u001b[38;5;241m.\u001b[39mcombinator\n\u001b[0;32m    634\u001b[0m     )\n\u001b[1;32m--> 635\u001b[0m clone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chain() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery\u001b[38;5;241m.\u001b[39mcombinator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery\u001b[38;5;241m.\u001b[39mcan_filter() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery\u001b[38;5;241m.\u001b[39mdistinct_fields:\n\u001b[0;32m    637\u001b[0m     clone \u001b[38;5;241m=\u001b[39m clone\u001b[38;5;241m.\u001b[39morder_by()\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\query.py:1476\u001b[0m, in \u001b[0;36mQuerySet.filter\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;124;03mReturn a new QuerySet instance with the args ANDed to the existing\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;124;03mset.\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_not_support_combined_queries(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_or_exclude\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\query.py:1494\u001b[0m, in \u001b[0;36mQuerySet._filter_or_exclude\u001b[1;34m(self, negate, args, kwargs)\u001b[0m\n\u001b[0;32m   1492\u001b[0m     clone\u001b[38;5;241m.\u001b[39m_deferred_filter \u001b[38;5;241m=\u001b[39m negate, args, kwargs\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1494\u001b[0m     \u001b[43mclone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_or_exclude_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clone\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\query.py:1501\u001b[0m, in \u001b[0;36mQuerySet._filter_or_exclude_inplace\u001b[1;34m(self, negate, args, kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query\u001b[38;5;241m.\u001b[39madd_q(\u001b[38;5;241m~\u001b[39mQ(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\sql\\query.py:1609\u001b[0m, in \u001b[0;36mQuery.add_q\u001b[1;34m(self, q_object)\u001b[0m\n\u001b[0;32m   1600\u001b[0m \u001b[38;5;66;03m# For join promotion this case is doing an AND for the added q_object\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m \u001b[38;5;66;03m# and existing conditions. So, any existing inner join forces the join\u001b[39;00m\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;66;03m# type to remain inner. Existing outer joins can however be demoted.\u001b[39;00m\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;66;03m# (Consider case where rel_a is LOUTER and rel_a__col=1 is added - if\u001b[39;00m\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;66;03m# rel_a doesn't produce any rows, then the whole condition must fail.\u001b[39;00m\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;66;03m# So, demotion is OK.\u001b[39;00m\n\u001b[0;32m   1606\u001b[0m existing_inner \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1607\u001b[0m     a \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malias_map \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malias_map[a]\u001b[38;5;241m.\u001b[39mjoin_type \u001b[38;5;241m==\u001b[39m INNER\n\u001b[0;32m   1608\u001b[0m }\n\u001b[1;32m-> 1609\u001b[0m clause, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mused_aliases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clause:\n\u001b[0;32m   1611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhere\u001b[38;5;241m.\u001b[39madd(clause, AND)\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\sql\\query.py:1641\u001b[0m, in \u001b[0;36mQuery._add_q\u001b[1;34m(self, q_object, used_aliases, branch_negated, current_negated, allow_joins, split_subq, check_filterable, summarize, update_join_types)\u001b[0m\n\u001b[0;32m   1637\u001b[0m joinpromoter \u001b[38;5;241m=\u001b[39m JoinPromoter(\n\u001b[0;32m   1638\u001b[0m     q_object\u001b[38;5;241m.\u001b[39mconnector, \u001b[38;5;28mlen\u001b[39m(q_object\u001b[38;5;241m.\u001b[39mchildren), current_negated\n\u001b[0;32m   1639\u001b[0m )\n\u001b[0;32m   1640\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m q_object\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[1;32m-> 1641\u001b[0m     child_clause, needed_inner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcan_reuse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mused_aliases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbranch_negated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbranch_negated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_negated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_negated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_joins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_joins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_subq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_subq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_filterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_filterable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m        \u001b[49m\u001b[43msummarize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummarize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupdate_join_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_join_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1652\u001b[0m     joinpromoter\u001b[38;5;241m.\u001b[39madd_votes(needed_inner)\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child_clause:\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\sql\\query.py:1555\u001b[0m, in \u001b[0;36mQuery.build_filter\u001b[1;34m(self, filter_expr, branch_negated, current_negated, can_reuse, allow_joins, split_subq, check_filterable, summarize, update_join_types)\u001b[0m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1553\u001b[0m     col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_col(targets[\u001b[38;5;241m0\u001b[39m], join_info\u001b[38;5;241m.\u001b[39mfinal_field, alias)\n\u001b[1;32m-> 1555\u001b[0m condition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlookups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1556\u001b[0m lookup_type \u001b[38;5;241m=\u001b[39m condition\u001b[38;5;241m.\u001b[39mlookup_name\n\u001b[0;32m   1557\u001b[0m clause \u001b[38;5;241m=\u001b[39m WhereNode([condition], connector\u001b[38;5;241m=\u001b[39mAND)\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\sql\\query.py:1385\u001b[0m, in \u001b[0;36mQuery.build_lookup\u001b[1;34m(self, lookups, lhs, rhs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lookup_class:\n\u001b[0;32m   1383\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1385\u001b[0m lookup \u001b[38;5;241m=\u001b[39m \u001b[43mlookup_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;66;03m# Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all\u001b[39;00m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;66;03m# uses of None as a query value unless the lookup supports it.\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup\u001b[38;5;241m.\u001b[39mrhs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lookup\u001b[38;5;241m.\u001b[39mcan_use_none_as_rhs:\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\lookups.py:30\u001b[0m, in \u001b[0;36mLookup.__init__\u001b[1;34m(self, lhs, rhs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lhs, rhs):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlhs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrhs \u001b[38;5;241m=\u001b[39m lhs, rhs\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prep_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_prep_lhs()\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlhs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_bilateral_transforms\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\lookups.py:369\u001b[0m, in \u001b[0;36mExact.get_prep_lookup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    366\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe QuerySet value for an exact lookup must be limited to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone result using slicing.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    368\u001b[0m         )\n\u001b[1;32m--> 369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prep_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\lookups.py:88\u001b[0m, in \u001b[0;36mLookup.get_prep_lookup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlhs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_field\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlhs\u001b[38;5;241m.\u001b[39moutput_field, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_prep_value\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 88\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlhs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_field\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prep_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrhs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrhs_is_direct_value():\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Value(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrhs)\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\fields\\__init__.py:2745\u001b[0m, in \u001b[0;36mUUIDField.get_prep_value\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   2743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_prep_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m   2744\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_prep_value(value)\n\u001b[1;32m-> 2745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huiwa\\.conda\\envs\\BidPilot_new_env\\Lib\\site-packages\\django\\db\\models\\fields\\__init__.py:2763\u001b[0m, in \u001b[0;36mUUIDField.to_python\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   2761\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m uuid\u001b[38;5;241m.\u001b[39mUUID(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{input_form: value})\n\u001b[0;32m   2762\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m-> 2763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mValidationError(\n\u001b[0;32m   2764\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_messages[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   2765\u001b[0m             code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2766\u001b[0m             params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value},\n\u001b[0;32m   2767\u001b[0m         )\n\u001b[0;32m   2768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[1;31mValidationError\u001b[0m: ['“3”不是一个有效的UUID']"
     ]
    }
   ],
   "source": [
    "# 准备测试所需的 user, project, file_record  (其中project与file_record关联)\n",
    "User = get_user_model()\n",
    "\n",
    "# 获取已存在的测试数据\n",
    "\n",
    "# 获取已存在的用户\n",
    "user = User.objects.get(phone='18501771516')\n",
    "print(f\"用户: {user.phone}\")\n",
    "        \n",
    "# 获取已存在的项目\n",
    "project = Project.objects.get(project_name='测试项目1')\n",
    "print(f\"项目: {project.project_name}\")\n",
    "        \n",
    "# 获取已存在的文件\n",
    "file_record = FileRecord.objects.get(id='')\n",
    "print(f\"文件: {file_record.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "场景1：创建分析并关联已有文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#清除‘测试分析1”\n",
    "DocumentAnalysis.objects.filter(title=\"测试分析1\").delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 创建文档分析实例 - 测试分析1\n",
    "doc_analysis = DocumentAnalysis.objects.create(\n",
    "    project=project,\n",
    "    title=\"测试分析1\",\n",
    "    created_by=user,\n",
    "    #analysis_questions=[\"资质要求\", \"技术参数\"]  # 示例分析问题\n",
    ")\n",
    "print(f\"创建文档分析: {doc_analysis.title} (ID: {doc_analysis.id})\")\n",
    "print(f\"初始状态: {doc_analysis.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 关联已有文件\n",
    "try:\n",
    "    doc_analysis.update_file_record(file_record)\n",
    "    print(f\"成功关联文件: {file_record.name}\")\n",
    "    #print(f\"提取的XML长度: {len(doc_analysis.raw_xml) if doc_analysis.raw_xml else 0}\")\n",
    "except Exception as e:\n",
    "    print(f\"关联文件失败: {str(e)}\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 提取元素\n",
    "extractor=DocxExtractor(doc_analysis)\n",
    "extractor.extract_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 打印元素\n",
    "from pprint import pprint\n",
    "Analysis1 = DocumentAnalysis.objects.get(id=doc_analysis.id)\n",
    "pprint(Analysis1.extracted_elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "场景2：创建分析并上传新文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#清除‘测试分析2”\n",
    "DocumentAnalysis.objects.filter(title=\"测试分析2\").delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 创建新的文档分析实例 - 测试分析2\n",
    "doc_analysis2 = DocumentAnalysis.objects.create(\n",
    "    project=project,\n",
    "    title=\"测试分析2\",\n",
    "    created_by=user,\n",
    "    analysis_questions=[\"投标要求\", \"评分标准\"]  # 示例分析问题\n",
    ")\n",
    "print(f\"创建文档分析: {doc_analysis2.title} (ID: {doc_analysis2.id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.上传真实的 DOCX文件\n",
    "\n",
    "# 2.1 准备文件路径\n",
    "doc_path = \"C:/Users/huiwa/Downloads/文本分析测试/CaseTest/case8：招标文件-第1包：一级压榨花生油.docx\"\n",
    "\n",
    "# 2.2 读取文件内容\n",
    "with open(doc_path, 'rb') as f:\n",
    "    file_content = f.read()\n",
    "test_file = SimpleUploadedFile(\n",
    "    \"test_doc.docx\",\n",
    "    file_content,\n",
    "    content_type=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
    ")\n",
    "print(f\"文件大小: {test_file.size}\")\n",
    "\n",
    "# 2. 创建新的文件记录 并 存储文件对象\n",
    "new_file_record = FileRecord.objects.create(\n",
    "    name=\"test_doc.docx\",\n",
    "    file=test_file,  # 使用之前准备的测试文件\n",
    "    owner=user,\n",
    "    size = test_file.size\n",
    ")\n",
    "print(f\"创建文件记录: {new_file_record.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 关联新文件\n",
    "try:\n",
    "    doc_analysis2.update_file_record(new_file_record)\n",
    "except Exception as e:\n",
    "    print(f\"关联文件失败: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 触发开始分析，并提取文档元素 elements 存入数据库\n",
    "print(\"\\n===== 最终状态检查 =====\")\n",
    "print(f\"开始分析前-状态: {doc_analysis2.status}\")\n",
    "doc_analysis2.start_analysis()\n",
    "print(f\"开始分析后-状态: {doc_analysis2.status}\")\n",
    "extractor2=DocxExtractor(doc_analysis2)\n",
    "extractor2.extract_elements();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange size=3> 文章结构分析 <font> <br>\n",
    "<font color=gray size=2> \n",
    "当我们分析招标文件时，首先会检视阅读，了解文档的框架和结构。<br>\n",
    "好的框架和结构，能让大模型更好地理解文档的上下文。 <br>\n",
    "具体到特定分析时，大模型能够根据框架结构，更准确地找到相关的内容。<br>\n",
    "\n",
    "这会带来两个好处：<br>\n",
    "1. 提升分析结果的准确性，避免无关内容带来的噪音影响<br>\n",
    "2. 减少大模型分析时使用的token数，降低成本。 <br>\n",
    "\n",
    "所以，我们会在这个环节，花一点时间和资源，来检视和校准文档的章节结构。<br>\n",
    "\n",
    "章节结构信息通常来自：<br>\n",
    "1. 文档开头的目录<br>\n",
    "2. 正文中的标题（H1,H2,H3）或文档大纲<br>\n",
    "\n",
    "理想情况下，它们的信息应该一致。如果不一致，就优先级而言，目录的优先级最高，其次是文档大纲，最后是标题。 <br>\n",
    "\n",
    "章节结构层级通常建议在2-3级，过高的层级会造成大模型在选择上下文时无所适从，而过多的层级则无法体现文档的结构化信息。这也是检视的重点。我们会结合章节的篇幅给予建议，并借助大模型来获得更多的章节信息。<br>\n",
    "\n",
    "最后，我们将向您交付章节结构的信息，您可以据此进行最终确认或进一步调整。 <br>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Django初始化\n",
    "import django_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关模型：get_user_model, Project, FileRecord, DocumentAnalysis, FileProjectLink, ProjectHistory\n",
    "from django.contrib.auth import get_user_model\n",
    "from apps.doc_analysis.models import DocumentAnalysis, InvalidStatusTransition\n",
    "from apps.projects.models import Project\n",
    "from apps.files.models import FileRecord\n",
    "from django.core.files.uploadedfile import SimpleUploadedFile\n",
    "from apps.doc_analysis.document_extractors import DocxExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备测试所需的 user, project, analysis \n",
    "User = get_user_model()\n",
    "# 获取已存在的用户\n",
    "user = User.objects.get(phone='18501771516')\n",
    "print(f\"用户: {user.phone}\")\n",
    "        \n",
    "# 获取已存在的项目\n",
    "project = Project.objects.get(project_name='测试项目1')\n",
    "print(f\"项目: {project.project_name}\")\n",
    "        \n",
    "#\n",
    "analysis2 = DocumentAnalysis.objects.get(title ='测试分析2',)\n",
    "print(f\"分析：{analysis2.title}\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从数据库提取文档元素 elements 用于分析\n",
    "elements = analysis2.extracted_elements\n",
    "from pprint import pprint\n",
    "print(f\"{len(elements)}个元素\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试用JSON作为输入的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组织JSON的input格式\n",
    "toc_elements = [elem for elem in elements if 'is_TOC' in elem]\n",
    "heading_elements = [elem for elem in elements if 'is_heading' in elem]\n",
    "import json\n",
    "formatted_toc_elements = json.dumps(toc_elements, ensure_ascii=False, indent=2)\n",
    "formatted_heading_elements = json.dumps(heading_elements, ensure_ascii=False, indent=2)\n",
    "#pprint(toc_elements)\n",
    "#pprint(heading_elements)\n",
    "#print(formatted_heading_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建context, 用文档内容用JSON表达\n",
    "context = f\"\"\" \n",
    "你是一个专业的文档结构分析助手。现在需要你帮助分析一份招标文档的目录结构和正文标题的一致性。\n",
    "\n",
    "输入数据说明：\n",
    "1. 目录标题元素(TOC)：从文档目录页提取的标题\n",
    "2. 正文标题元素(Heading)：从文档正文中提取的标题\n",
    "\n",
    "文档元素字段说明：\n",
    "- type: 元素类型 (paragraph/table/figure)\n",
    "- positions: 元素在文档中的位置\n",
    "- content: 元素的文本内容\n",
    "- is_TOC: 标识目录元素 (True)\n",
    "- TOC_level: 目录标题层级 (chapter/section/subsection/other)\n",
    "- is_heading: 标识正文标题 (True)\n",
    "- heading_level: 正文标题层级 (chapter/section/subsection/other)\n",
    "\n",
    "输入数据：\n",
    "目录标题列表：\n",
    "{formatted_toc_elements}\n",
    "\n",
    "正文标题列表：\n",
    "{formatted_heading_elements}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建要求 requirement\n",
    "requirement = \"\"\"\n",
    "以<目录标题列表>为标准，检查<正文标题列表>中：\n",
    "1. 需要添加哪些标题？\n",
    "2. 需要删除哪些标题？\n",
    "3. 哪些标题的章节层级需要调整？\n",
    "\n",
    "目标：使<正文标题列表>与<目录标题列表>完全一致\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建输出格式 json\n",
    "output_format = \"\"\"\n",
    "{{\n",
    "    \"conclusion\": \"总体分析结论，包括不一致的数量统计和主要问题\",\n",
    "    \"delete_headings\": [\n",
    "        {{\n",
    "            \"content\": \"需要删除的正文标题内容\",\n",
    "            \"position\": \"标题在文档中的位置\",\n",
    "            \"action\": \"删除该正文标题的标题格式\",\n",
    "            \"reason\": \"建议删除的具体原因\"\n",
    "        }}\n",
    "    ],\n",
    "    \"add_headings\": [\n",
    "        {{\n",
    "            \"content\": \"需要添加的目录标题内容\",\n",
    "            \"position\": \"建议添加位置\",\n",
    "            \"action\": \"在指定位置添加标题格式\",\n",
    "            \"reason\": \"建议添加的具体原因\"\n",
    "        }}\n",
    "    ],\n",
    "    \"adjust_levels\": [\n",
    "        {{\n",
    "            \"content\": \"需要调整层级的标题内容\",\n",
    "            \"position\": \"标题在文档中的位置\",\n",
    "            \"current_level\": \"当前层级\",\n",
    "            \"target_level\": \"目标层级\",\n",
    "            \"reason\": \"层级调整的原因\"\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "注意事项：\n",
    "1. 分析结果必须严格遵循指定的JSON格式\n",
    "2. 所有建议需要具体且可操作\n",
    "3. 不要在JSON之外输出任何内容\n",
    "4. 确保position信息准确，便于后续定位修改\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟输入给大模型的prompt：整合了context, requirement 和 output_format\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = f\"\"\"\n",
    "请分析以下招标文档内容，并根据要求给出分析结果：\n",
    "                \n",
    "###招标文档内容:\n",
    "{context}\n",
    "                \n",
    "###分析任务:\n",
    "{requirement}\n",
    "                \n",
    "###请严格按照以下JSON格式输出分析结果，不要在JSON格式外输出任何MARKDOWN的标记和内容：\n",
    "{output_format}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印文档目录\n",
    "print(\"====== 文档目录 ======\")\n",
    "for elem in elements:\n",
    "    if elem['is_toc'] == True:\n",
    "        print(f\"{elem['sequence_number']}  {elem['content'][:30]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印章节标题\n",
    "print(\"====== 文档大纲标题 ======\")\n",
    "for elem in elements:\n",
    "    if elem['is_heading'] == True:\n",
    "        print(f\"{elem['sequence_number']}  {elem['content'][:30]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用deepseek-v3进行测试\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from apps.doc_analysis.llm_services import BidAnalysisService\n",
    "from apps.doc_analysis.llm_services import AnalysisRequest \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "bid_llm_analyzer = BidAnalysisService(model_name=\"deepseek-v3\")\n",
    "analysis_request = AnalysisRequest(\n",
    "    context = context,\n",
    "    requirement = requirement,\n",
    "    output_format= output_format,\n",
    ")\n",
    "print(type(analysis_request.__dict__))\n",
    "\n",
    "response = asyncio.run(bid_llm_analyzer.outline_analysis(analysis_request,stream=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用qwen-plus进行测试\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from apps.doc_analysis.llm_services import BidAnalysisService\n",
    "from apps.doc_analysis.llm_services import AnalysisRequest \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "bid_llm_analyzer = BidAnalysisService(model_name=\"qwen-plus\")\n",
    "analysis_request = AnalysisRequest(\n",
    "    context = context,\n",
    "    requirement = requirement,\n",
    "    output_format= output_format,\n",
    ")\n",
    "print(type(analysis_request.__dict__))\n",
    "\n",
    "response = asyncio.run(bid_llm_analyzer.outline_analysis(analysis_request,stream=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试用文本作为输入的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_toc_strings = [\n",
    "    f\"[{elem[\"position\"]}], {elem[\"TOC_level\"]}, 标题：{elem[\"content\"]}\"\n",
    "    for elem in elements\n",
    "    if elem.get('is_TOC') is True\n",
    "]\n",
    "formatted_TOC_strs = \"\\n\".join(formatted_toc_strings)\n",
    "print(formatted_TOC_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_heading_strings = [\n",
    "    f\"[{elem[\"position\"]}], {elem[\"heading_level\"]}, 标题：{elem[\"content\"]}\"\n",
    "    for elem in elements\n",
    "    if elem.get('is_heading') is True\n",
    "]\n",
    "formatted_haadings_strs = \"\\n\".join(formatted_heading_strings)\n",
    "print(formatted_haadings_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建context, 用文档内容用JSON表达\n",
    "context2 = f\"\"\" \n",
    "1. 目录标题列表：从文档目录中提取的标题\n",
    "2. 正文标题列表：从文档正文中提取的标题\n",
    "\n",
    "数据格式：\n",
    "\"[文档位置], 章节类型, 标题内容\"\n",
    "\n",
    "输入数据：\n",
    "1. <目录标题列表>：\n",
    "{formatted_TOC_strs}\n",
    "\n",
    "2. <正文标题列表>：\n",
    "{formatted_haadings_strs}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(context2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建要求 requirement\n",
    "requirement2 = \"\"\"\n",
    "以<目录标题列表>为标准，检查<正文标题列表>中：\n",
    "1. 需要添加哪些标题？\n",
    "2. 需要删除哪些标题？\n",
    "3. 哪些标题的章节层级需要调整？\n",
    "\n",
    "目标：使<正文标题列表>与<目录标题列表>完全一致\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建输出格式 json\n",
    "output_format2 = \"\"\"\n",
    "请严格按照以下JSON格式输出分析结果，不要在JSON格式外输出任何MARKDOWN的标记和内容：\n",
    "{\n",
    "    \"conclusion\": \"总体分析结论，包括不一致的数量统计和主要问题\",\n",
    "    \"headings_to_delete\": [\n",
    "        {\n",
    "            \"content\": \"需要删除的正文标题内容\",\n",
    "            \"position\": \"标题在文档中的位置\",\n",
    "            \"action\": \"删除该正文标题的标题格式\",\n",
    "            \"reason\": \"建议删除的具体原因\"\n",
    "        }\n",
    "    ],\n",
    "    \"headings_to_add\": [\n",
    "        {\n",
    "            \"content\": \"需要添加的目录标题内容\",\n",
    "            \"position\": \"建议添加位置\",\n",
    "            \"action\": \"在指定位置添加标题格式\",\n",
    "            \"reason\": \"建议添加的具体原因\"\n",
    "        }\n",
    "    ],\n",
    "    \"levels_to_adjust\": [\n",
    "        {\n",
    "            \"content\": \"需要调整层级的标题内容\",\n",
    "            \"position\": \"标题在文档中的位置\",\n",
    "            \"current_level\": \"当前层级\",\n",
    "            \"target_level\": \"目标层级\",\n",
    "            \"reason\": \"层级调整的原因\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "### 注意事项\n",
    "1. 分析结果必须严格遵循指定的JSON格式\n",
    "2. 所有建议需要具体且可操作\n",
    "3. 不要在JSON格式外输出任何内容\n",
    "4. 确保position信息准确，便于后续定位修改\n",
    "5. 优先以目录标题为准进行匹配\n",
    "6. 忽略空格、换行等格式字符的差异\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟输入给大模型的prompt：整合了context, requirement 和 output_format\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt2 = f\"\"\"\n",
    "请分析以下招标文档内容，并根据要求给出分析结果：\n",
    "                \n",
    "### 输入数据说明:\n",
    "{context2}\n",
    "\n",
    "### 分析任务:\n",
    "{requirement2}\n",
    "                \n",
    "### 输出要求\n",
    "{output_format2}\n",
    "\"\"\"\n",
    "\n",
    "print(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用deepseek-v3进行测试\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from apps.doc_analysis.llm_services import BidAnalysisService\n",
    "from apps.doc_analysis.llm_services import AnalysisRequest \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "bid_llm_analyzer = BidAnalysisService(model_name=\"deepseek-v3\")\n",
    "analysis_request = AnalysisRequest(\n",
    "    context = context2,\n",
    "    requirement = requirement2,\n",
    "    output_format= output_format2,\n",
    ")\n",
    "print(type(analysis_request.__dict__))\n",
    "\n",
    "response = asyncio.run(bid_llm_analyzer.outline_analysis(analysis_request,stream=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用qwen-plus进行测试\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from apps.doc_analysis.llm_services import BidAnalysisService\n",
    "from apps.doc_analysis.llm_services import AnalysisRequest \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "bid_llm_analyzer = BidAnalysisService(model_name=\"qwen-plus\")\n",
    "analysis_request = AnalysisRequest(\n",
    "    context = context2,\n",
    "    requirement = requirement2,\n",
    "    output_format= output_format2,\n",
    ")\n",
    "print(type(analysis_request.__dict__))\n",
    "\n",
    "response = asyncio.run(bid_llm_analyzer.outline_analysis(analysis_request,stream=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简化模型任务测试 - 只找不同，不分析，不给建议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建要求 requirement\n",
    "requirement3 = \"\"\"\n",
    "请对比<目录标题列表>和<正文标题列表>的标题内容，找出以下三类不同标题项：\n",
    "1. 目录列表里有，但正文里没有的标题项\n",
    "2. 目录列表里没有，但正文里有的标题项\n",
    "3. 目录和正文都有，但章节层级不同的标题项\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建输出格式 json\n",
    "output_format3 = \"\"\"\n",
    "请严格按照以下JSON格式输出分析结果，不要在JSON格式外输出任何MARKDOWN的标记和内容：\n",
    "{\n",
    "    \"TOC_only_elements\": [\n",
    "        {\n",
    "            \"position\": \"目录独有的标题在文档中的位置\",\n",
    "            \"content\": \"目录独有的标题的内容\",\n",
    "        }\n",
    "    ],\n",
    "    \"heading_only_elements\": [\n",
    "        {\n",
    "            \"position\": \"正文独有的标题项在文档中的位置\",\n",
    "            \"content\": \"正文独有的标题的内容\",\n",
    "\n",
    "        }\n",
    "    ],\n",
    "    \"levels_different: [\n",
    "        {  \n",
    "            \"position_toc\": \"目录标题在文档中位置\",\n",
    "            \"content_toc\": \"目录的标题内容\",\n",
    "            \"toc_level\": \"目录的标题的章节层级\",\n",
    "            \"position_heading\":\"正文标题在文档中的位置\", \n",
    "            \"content_toc\": \"正文的标题内容\",\n",
    "            \"heading_level\": \"正文标题的章节层级\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "### 注意事项\n",
    "1. 分析结果必须严格遵循指定的JSON格式\n",
    "2. 不要在JSON格式外输出任何内容\n",
    "3. 确保position信息准确，便于后续定位修改\n",
    "4. 优先以目录标题为准进行匹配\n",
    "5. 忽略空格、换行等格式字符的差异\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用deepseek-v3进行测试\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from apps.doc_analysis.llm_services import BidAnalysisService\n",
    "from apps.doc_analysis.llm_services import AnalysisRequest \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "bid_llm_analyzer = BidAnalysisService(model_name=\"deepseek-v3\")\n",
    "analysis_request = AnalysisRequest(\n",
    "    context = context2,\n",
    "    requirement = requirement3,\n",
    "    output_format= output_format3,\n",
    ")\n",
    "print(type(analysis_request.__dict__))\n",
    "\n",
    "response = asyncio.run(bid_llm_analyzer.outline_analysis(analysis_request,stream=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用qwen-plus进行测试\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from apps.doc_analysis.llm_services import BidAnalysisService\n",
    "from apps.doc_analysis.llm_services import AnalysisRequest \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "bid_llm_analyzer = BidAnalysisService(model_name=\"qwen-plus\")\n",
    "analysis_request = AnalysisRequest(\n",
    "    context = context2,\n",
    "    requirement = requirement3,\n",
    "    output_format= output_format3,\n",
    ")\n",
    "print(type(analysis_request.__dict__))\n",
    "\n",
    "response = asyncio.run(bid_llm_analyzer.outline_analysis(analysis_request,stream=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新组织数据；将chapter, section 分开，不比对层级不同。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_toc_chapters = [\n",
    "    f\"[{elem[\"position\"]}], {elem[\"TOC_level\"]}, 标题：{elem[\"content\"]}\"\n",
    "    for elem in elements\n",
    "    if elem.get('TOC_level') == \"chapter\"\n",
    "]\n",
    "formatted_TOC_chapters_strs = \"\\n\".join(formatted_toc_chapters)\n",
    "print(formatted_TOC_chapters_strs)\n",
    "\n",
    "print(\"=============\")\n",
    "\n",
    "formatted_heading_chapters = [\n",
    "    f\"[{elem[\"position\"]}], {elem[\"heading_level\"]}, 标题：{elem[\"content\"]}\"\n",
    "    for elem in elements\n",
    "    if elem.get('heading_level') == \"chapter\"\n",
    "]\n",
    "formatted_heading_chapters_strs = \"\\n\".join(formatted_heading_chapters)\n",
    "print(formatted_heading_chapters_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_toc_sections = [\n",
    "    f\"[{elem[\"position\"]}], {elem[\"TOC_level\"]}, 标题：{elem[\"content\"]}\"\n",
    "    for elem in elements\n",
    "    if elem.get('TOC_level') == \"section\"\n",
    "]\n",
    "formatted_TOC_sections_strs = \"\\n\".join(formatted_toc_sections)\n",
    "print(formatted_TOC_sections_strs)\n",
    "\n",
    "print(\"=============\")\n",
    "\n",
    "formatted_heading_sections = [\n",
    "    f\"[{elem[\"position\"]}], {elem[\"heading_level\"]}, 标题：{elem[\"content\"]}\"\n",
    "    for elem in elements\n",
    "    if elem.get('heading_level') == \"section\"\n",
    "]\n",
    "formatted_heading_sections_strs = \"\\n\".join(formatted_heading_sections)\n",
    "print(formatted_heading_sections_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_toc_subsections = [\n",
    "    f\"[{elem[\"position\"]}], {elem[\"TOC_level\"]}, 标题：{elem[\"content\"]}\"\n",
    "    for elem in elements\n",
    "    if elem.get('TOC_level') == \"subsection\"\n",
    "]\n",
    "formatted_TOC_subsections_strs = \"\\n\".join(formatted_toc_subsections)\n",
    "print(formatted_TOC_subsections_strs)\n",
    "\n",
    "print(\"=============\")\n",
    "\n",
    "formatted_heading_subsections = [\n",
    "    f\"[{elem[\"position\"]}], {elem[\"heading_level\"]}, 标题：{elem[\"content\"]}\"\n",
    "    for elem in elements\n",
    "    if elem.get('heading_level') == \"subsection\"\n",
    "]\n",
    "formatted_heading_subsections_strs = \"\\n\".join(formatted_heading_subsections)\n",
    "print(formatted_heading_subsections_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建context, 用文档内容用JSON表达\n",
    "context4 = f\"\"\" \n",
    "1. 目录标题列表：从文档目录中提取的标题\n",
    "2. 正文标题列表：从文档正文中提取的标题\n",
    "\n",
    "数据格式：\n",
    "\"[文档位置], 章节类型, 标题内容\"\n",
    "\n",
    "输入数据：\n",
    "1. <目录标题列表>：\n",
    "{formatted_TOC_chapters_strs}\n",
    "\n",
    "2. <正文标题列表>：\n",
    "{formatted_heading_chapters_strs}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(context4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建要求 requirement\n",
    "requirement4 = \"\"\"\n",
    "请对比<目录标题列表>和<正文标题列表>的标题内容，找出以下三类不同标题项：\n",
    "1. 目录列表里有，但正文里没有的标题项\n",
    "2. 目录列表里没有，但正文里有的标题项\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建输出格式 json\n",
    "output_format4 = \"\"\"\n",
    "请严格按照以下JSON格式输出分析结果，不要在JSON格式外输出任何MARKDOWN的标记和内容：\n",
    "如果无符合条件的标题项，请留空，即[]\n",
    "{\n",
    "    \"TOC_only_elements\": [\n",
    "        {\n",
    "            \"position\": \"目录独有的标题在文档中的位置\",\n",
    "            \"content\": \"目录独有的标题的内容\",\n",
    "            \"reason\": \"选择的原因\"\n",
    "        }\n",
    "    ],\n",
    "    \"heading_only_elements\": [\n",
    "        {\n",
    "            \"position\": \"正文独有的标题项在文档中的位置\",\n",
    "            \"content\": \"正文独有的标题的内容\",\n",
    "            \"reason\": \"选择的原因\"\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "### 注意事项\n",
    "1. 分析结果必须严格遵循指定的JSON格式\n",
    "2. 不要在JSON格式外输出任何内容\n",
    "3. 确保position信息准确，便于后续定位修改\n",
    "4. 优先以目录标题为准进行匹配\n",
    "5. 忽略空格、换行等格式字符的差异\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用qwen-plus进行测试\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from apps.doc_analysis.llm_services import BidAnalysisService\n",
    "from apps.doc_analysis.llm_services import AnalysisRequest \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "bid_llm_analyzer = BidAnalysisService(model_name=\"qwen-plus\")\n",
    "analysis_request = AnalysisRequest(\n",
    "    context = context4,\n",
    "    requirement = requirement4,\n",
    "    output_format= output_format4,\n",
    ")\n",
    "print(type(analysis_request.__dict__))\n",
    "\n",
    "response = asyncio.run(bid_llm_analyzer.outline_analysis(analysis_request,stream=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建context, 用文档内容用JSON表达\n",
    "context5 = f\"\"\" \n",
    "1. 目录标题列表：从文档目录中提取的标题\n",
    "2. 正文标题列表：从文档正文中提取的标题\n",
    "\n",
    "数据格式：\n",
    "\"[文档位置], 章节类型, 标题内容\"\n",
    "\n",
    "输入数据：\n",
    "1. <目录标题列表>：\n",
    "{formatted_TOC_sections_strs}\n",
    "\n",
    "2. <正文标题列表>：\n",
    "{formatted_heading_sections_strs}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(context5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用qwen-plus进行测试\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from apps.doc_analysis.llm_services import BidAnalysisService\n",
    "from apps.doc_analysis.llm_services import AnalysisRequest \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "bid_llm_analyzer = BidAnalysisService(model_name=\"qwen-plus\")\n",
    "analysis_request = AnalysisRequest(\n",
    "    context = context5,\n",
    "    requirement = requirement4,\n",
    "    output_format= output_format4,\n",
    ")\n",
    "print(type(analysis_request.__dict__))\n",
    "\n",
    "response = asyncio.run(bid_llm_analyzer.outline_analysis(analysis_request,stream=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建context, 用文档内容用JSON表达\n",
    "context6 = f\"\"\" \n",
    "1. 目录标题列表：从文档目录中提取的标题\n",
    "2. 正文标题列表：从文档正文中提取的标题\n",
    "\n",
    "数据格式：\n",
    "\"[文档位置], 章节类型, 标题内容\"\n",
    "\n",
    "输入数据：\n",
    "1. <目录标题列表>：\n",
    "{formatted_TOC_subsections_strs}\n",
    "\n",
    "2. <正文标题列表>：\n",
    "{formatted_heading_subsections_strs}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(context6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用qwen-plus进行测试\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from apps.doc_analysis.llm_services import BidAnalysisService\n",
    "from apps.doc_analysis.llm_services import AnalysisRequest \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "bid_llm_analyzer = BidAnalysisService(model_name=\"qwen-plus\")\n",
    "analysis_request = AnalysisRequest(\n",
    "    context = context6,\n",
    "    requirement = requirement4,\n",
    "    output_format= output_format4,\n",
    ")\n",
    "print(type(analysis_request.__dict__))\n",
    "\n",
    "response = asyncio.run(bid_llm_analyzer.outline_analysis(analysis_request,stream=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大纲分析1： vs 目录分析、用户确认、并采取行动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入分析器，并进行大纲分析，返回分析结果results\n",
    "from apps.doc_analysis.outline_analyzer import DocumentOutlineAnalyzer\n",
    "OutlineAnalyzer = DocumentOutlineAnalyzer(elements)\n",
    "results = OutlineAnalyzer.compare_toc_and_outline()\n",
    "# 打印分析结果\n",
    "print(f\"目录但非大纲标题的元素: {len(results['toc_only'])}\")\n",
    "print(f\"大纲标题但非目录的元素: {len(results['outline_only'])}\")\n",
    "print(f\"大纲标题层级与目录标题层级不匹配元素:{len(results['level_differences'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成建议 suggetions\n",
    "suggestions = OutlineAnalyzer.outline_suggestions(results)\n",
    "pprint(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#采纳建议 - 模拟\n",
    "# confirmed_suggestions 来自用户前端\n",
    "\n",
    "confirmed_suggestions=[]\n",
    "for suggestion in suggestions:\n",
    "    suggestion['confirmed'] = True\n",
    "    confirmed_suggestions.append(suggestion)\n",
    "pprint(confirmed_suggestions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#执行用户确认好的建议：\n",
    "corrected_elements = OutlineAnalyzer.correct_outline(elements,confirmed_suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutlineAnalyzer = DocumentOutlineAnalyzer(corrected_elements)\n",
    "corrected_results = OutlineAnalyzer.compare_toc_and_outline()\n",
    "# 打印分析结果\n",
    "print(f\"目录但非大纲标题的元素: {len(corrected_results['toc_only'])}\")\n",
    "print(f\"大纲标题但非目录的元素: {len(corrected_results['outline_only'])}\")\n",
    "print(f\"大纲标题层级与目录标题层级不匹配元素:{len(corrected_results['level_differences'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大纲分析2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutlineAnalyzer.print_analysis_results(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in elements:\n",
    "    if elem['element_type'] == 'ElementType.PARAGRAPH':\n",
    "        print(f\"{elem['sequence_number']}  {elem['content'][:30]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(elements[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.doc_analysis.docx_parser._03_element_extractor import ElementType, DocumentElement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_type = elements[0]['element_type']\n",
    "print(type(ele_type),ele_type)\n",
    "ele_sequence_number = elements[0]['sequence_number']\n",
    "print(type(ele_sequence_number), ele_sequence_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements[0]['element_type'] == 'ElementType.PARAGRAPH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.doc_analysis.doc_structurer._03_tree_builder import TreeBuilder\n",
    "from apps.doc_analysis.doc_structurer.doc_tree_retriever import DocTreeRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_builder = TreeBuilder(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_structure = tree_builder.build_to_level(target_level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>1. 测试分析模型 Models.py：创建和状态自动更新<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建文档分析\n",
    "analyses = DocumentAnalysis.objects.filter(project=project, file_record=file_record)\n",
    "isAnalysisExist = analyses.exists()\n",
    "if isAnalysisExist:\n",
    "    print(f\"分析已存在，跳过创建\")\n",
    "    this_analysis = analyses.filter(title=\"测试分析\")\n",
    "    this_analysis.update(status=DocumentAnalysis.AnalysisStatus.PENDING)\n",
    "    print(f\"初始化文档分析为PENDING状态: {this_analysis.first().status}\")\n",
    "\n",
    "else:\n",
    "    analysis = DocumentAnalysis.objects.create(\n",
    "        title=\"测试分析\",\n",
    "        project=project,\n",
    "        file_record=file_record,\n",
    "        created_by=user\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印分析列表\n",
    "analyses = DocumentAnalysis.objects.filter(title__startswith='测试分析')\n",
    "for analysis in analyses:\n",
    "    print(f\"分析号:{analysis.id}\\n\",\n",
    "          f\"分析名称：{analysis.title}\\n\",\n",
    "          f\"分析所在项目：{analysis.project.project_name}\\n\", \n",
    "          f\"分析的文件：{analysis.file_record.name}\\n\" ,\n",
    "          f\"分析的阶段：{analysis.status}\\n\",\n",
    "          f\"分析的问题：{analysis.analysis_questions}\\n\",\n",
    "          f\"分析结果：{analysis.analysis_result}\\n\",\n",
    "          f\"分析创建者：{analysis.created_by.phone}\\n\",\n",
    "          f\"分析用时：{analysis.processing_time}\\n\",\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试状态转换流程\n",
    "if analysis.status == DocumentAnalysis.AnalysisStatus.PENDING:\n",
    "    print(\"1.可以测试文档分析从PENDING到PROCESSING的流转：\")\n",
    "    analysis.start_analysis()\n",
    "    print(f\"开始分析后状态: {analysis.status}\")\n",
    "else:\n",
    "    print(f\"1. 测试文档分析状态在{analysis.status}，不能使用start_analysis()方法\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟分析结果\n",
    "sample_result = [\n",
    "    {\n",
    "        \"question\": \"资质要求\",\n",
    "        \"answer\": \"需要具备建筑施工总承包特级资质\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"技术参数\",\n",
    "        \"answer\": \"项目规模：建筑面积50000平方米\"\n",
    "    }\n",
    "]\n",
    "# 完成分析\n",
    "if analysis.status == DocumentAnalysis.AnalysisStatus.PROCESSING:\n",
    "    print(\"2.可以测试文档分析从PROCESSING到COMPLETED的流转：\")\n",
    "    analysis.complete_analysis(result=sample_result)\n",
    "    print(f\"完成分析后状态: {analysis.status}\")\n",
    "\n",
    "else:\n",
    "    print(f\"2. 测试文档分析状态在{analysis.status}，不能使用complete_analysis()方法\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确认分析结果\n",
    "confirmed_results = [\n",
    "    {\n",
    "        \"question\": \"资质要求\",\n",
    "        \"answer\": \"需要具备建筑施工总承包特级资质\",\n",
    "        \"comment\": \"确认无误\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"技术参数\",\n",
    "        \"answer\": \"项目规模：建筑面积50000平方米\",\n",
    "        \"comment\": \"数据已核实\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 完成分析\n",
    "if analysis.status == DocumentAnalysis.AnalysisStatus.COMPLETED:\n",
    "    print(\"3.可以测试文档分析从COMPLETED到CONFIRMED的流转：\")\n",
    "    analysis.confirm_analysis(user=user, confirmed_results=confirmed_results)\n",
    "    print(f\"完成分析后状态: {analysis.status}\")\n",
    "\n",
    "else:\n",
    "    print(f\"3. 测试文档分析状态在{analysis.status}，不能使用confirm_analysis()方法\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试错误状态转换\n",
    "print(\"\\n2. 测试错误状态转换处理：\")\n",
    "try:\n",
    "    # 创建新的分析实例用于测试失败场景\n",
    "    failed_analysis = DocumentAnalysis.objects.create(\n",
    "        title=\"测试失败分析\",\n",
    "        project=project,\n",
    "        file_record=file_record,\n",
    "        created_by=user\n",
    "    )\n",
    "    print(f\"创建失败分析的状态: {failed_analysis.status}\")\n",
    "    # 直接尝试确认一个未完成的分析\n",
    "    failed_analysis.confirm_analysis(user=user, confirmed_results=[])\n",
    "except InvalidStatusTransition as e:\n",
    "    print(f\"预期的错误捕获: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failed_analysis.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试失败流程\n",
    "failed_analysis.start_analysis()\n",
    "failed_analysis.fail_analysis(error_message=\"文档格式不支持\")\n",
    "print(f\"失败分析状态: {failed_analysis.status}\")\n",
    "print(f\"错误信息: {failed_analysis.error_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看分析结果\n",
    "print(\"\\n3. 查看最终分析结果：\")\n",
    "final_analysis = DocumentAnalysis.objects.get(id=analysis.id)\n",
    "print(f\"分析标题: {final_analysis.title}\")\n",
    "print(f\"当前状态: {final_analysis.status}\")\n",
    "print(f\"分析结果: {final_analysis.analysis_result}\")\n",
    "print(f\"确认时间: {final_analysis.confirmed_at}\")\n",
    "print(f\"确认用户: {final_analysis.confirmed_by.phone}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>2.Serializers.py测试<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.doc_analysis.serializers import ( \n",
    "    DocumentAnalysisBaseSerializer, \n",
    "    DocumentAnalysisCreateSerializer,\n",
    "    AnalysisResultUpdateSerializer,\n",
    "    AnalysisConfirmationSerializer,\n",
    "    DocumentAnalysisDisplaySerializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备测试数据\n",
    "test_file = FileRecord.objects.get(id='2')\n",
    "test_project = Project.objects.get(project_name='测试项目1')\n",
    "test_user = User.objects.get(phone='18501771516')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟请求类\n",
    "class MockRequest:\n",
    "    def __init__(self, user=None):\n",
    "        self.user = test_user\n",
    "        self.method = 'POST'  # 可以根据需要设置请求方法\n",
    "        self.META = {}        # 请求元数据\n",
    "        self.session = {}     # 会话数据\n",
    "\n",
    "# 创建模拟请求实例\n",
    "mock_request = MockRequest(user=test_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 测试创建序列化器\n",
    "print(\"=== 测试创建序列化器 ===\")\n",
    "create_data = {\n",
    "    \"project_id\": test_project.id,\n",
    "    \"file_record_id\": test_file.id,\n",
    "    \"title\": \"序列化器测试分析\",\n",
    "    \"analysis_questions\": [\"资质要求\", \"技术参数\"]\n",
    "}\n",
    "\n",
    "create_serializer = DocumentAnalysisCreateSerializer(\n",
    "    data=create_data,\n",
    "    context={'request': MockRequest()}\n",
    ")\n",
    "\n",
    "if create_serializer.is_valid():\n",
    "    new_analysis = create_serializer.save()\n",
    "    print(f\"✅ 创建成功 - ID: {new_analysis.id}\")\n",
    "else:\n",
    "    print(f\"❌ 创建失败 - 错误: {create_serializer.errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印new_analysis\n",
    "for analysis in [new_analysis]:\n",
    "    print(f\"分析号:{analysis.id}\\n\",\n",
    "          f\"分析名称：{analysis.title}\\n\",\n",
    "          f\"分析所在项目：{analysis.project.project_name}\\n\", \n",
    "          f\"分析的文件：{analysis.file_record.name}\\n\" ,\n",
    "          f\"分析的阶段：{analysis.status}\\n\",\n",
    "          f\"分析的问题：{analysis.analysis_questions}\\n\",\n",
    "          f\"分析结果：{analysis.analysis_result}\\n\",\n",
    "          f\"分析创建者：{analysis.created_by.phone}\\n\",\n",
    "          f\"分析用时：{analysis.processing_time}\\n\",\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试无效文件类型\n",
    "print(\"\\n测试无效文件类型:\")\n",
    "invalid_file = FileRecord.objects.create(\n",
    "    name=\"test.txt\",\n",
    "    type=\"TXT\",\n",
    "    size=1024,\n",
    "    owner=test_user,  # 添加必需的owner字段\n",
    "    version=1,        # 添加必需的version字段\n",
    "    processing_status='NONE',  # 添加必需的processing_status字段\n",
    "    created_by=test_user.phone  # 添加必需的created_by字段\n",
    ")\n",
    "\n",
    "invalid_data = create_data.copy()\n",
    "invalid_data[\"file_record_id\"] = invalid_file.id\n",
    "\n",
    "invalid_serializer = DocumentAnalysisCreateSerializer(\n",
    "    data=invalid_data,\n",
    "    context={'request': mock_request}\n",
    ")\n",
    "\n",
    "if not invalid_serializer.is_valid():\n",
    "    print(f\"✅ 正确捕获错误: {invalid_serializer.errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 测试结果更新序列化器\n",
    "print(\"\\n=== 测试结果更新序列化器 ===\")\n",
    "update_data = {\n",
    "\n",
    "            \"question\": \"资质要求\",\n",
    "            \"answer\": \"需要具备建筑施工总承包特级资质\",\n",
    "            \"context\": [\"上下文段落1\", \"上下文段落2\"],\n",
    "            \"confidence\": 0.95\n",
    "        }\n",
    "\n",
    "result_serializer = AnalysisResultUpdateSerializer(\n",
    "    instance=new_analysis,\n",
    "    data=update_data,\n",
    "    context={'request': mock_request}\n",
    ")\n",
    "\n",
    "if result_serializer.is_valid():\n",
    "    updated = result_serializer.save()\n",
    "    print(f\"✅ 结果更新成功 - 最新结果: {updated.analysis_result[-1]}\")\n",
    "else:\n",
    "    print(f\"❌ 更新失败 - 错误: {result_serializer.errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 测试确认序列化器\n",
    "print(\"\\n=== 测试确认序列化器 ===\")\n",
    "confirmation_data = {\n",
    "            \"question\": \"资质要求\",\n",
    "            \"answer\": \"需要具备建筑施工总承包特级资质\",\n",
    "            \"comment\": \"测试确认\"\n",
    "        }\n",
    "\n",
    "\n",
    "confirmation_serializer = AnalysisConfirmationSerializer(\n",
    "    instance=new_analysis,\n",
    "    data=confirmation_data,\n",
    "    context={'request': mock_request}\n",
    ")\n",
    "\n",
    "if confirmation_serializer.is_valid():\n",
    "    confirmed = confirmation_serializer.save()\n",
    "    print(f\"✅ 确认成功 - 状态: {confirmed.status}\")\n",
    "    print(f\"确认信息: {confirmed.analysis_result[0].get('confirmation')}\")\n",
    "else:\n",
    "    print(f\"❌ 确认失败 - 错误: {confirmation_serializer.errors}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BidPilot_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
