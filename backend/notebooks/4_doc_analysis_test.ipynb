{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>测试初始化<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Django初始化\n",
    "import django_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关模型：get_user_model, Project, FileRecord, DocumentAnalysis, FileProjectLink, ProjectHistory\n",
    "from django.contrib.auth import get_user_model\n",
    "from apps.doc_analysis.models import DocumentAnalysis, InvalidStatusTransition\n",
    "from apps.projects.models import Project\n",
    "from apps.files.models import FileRecord\n",
    "from django.core.files.uploadedfile import SimpleUploadedFile\n",
    "from apps.doc_analysis.document_extractors import DocxExtractor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备测试所需的 user, project, file_record  (其中project与file_record关联)\n",
    "User = get_user_model()\n",
    "\n",
    "# 获取已存在的测试数据\n",
    "\n",
    "# 获取已存在的用户\n",
    "user = User.objects.get(phone='18501771516')\n",
    "print(f\"用户: {user.phone}\")\n",
    "        \n",
    "# 获取已存在的项目\n",
    "project = Project.objects.get(project_name='测试项目1')\n",
    "print(f\"项目: {project.project_name}\")\n",
    "        \n",
    "# 获取已存在的文件\n",
    "file_record = FileRecord.objects.get(id='3')\n",
    "print(f\"文件: {file_record.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "场景1：创建分析并关联已有文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#清除‘测试分析1”\n",
    "DocumentAnalysis.objects.filter(title=\"测试分析1\").delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 创建文档分析实例 - 测试分析1\n",
    "doc_analysis = DocumentAnalysis.objects.create(\n",
    "    project=project,\n",
    "    title=\"测试分析1\",\n",
    "    created_by=user,\n",
    "    #analysis_questions=[\"资质要求\", \"技术参数\"]  # 示例分析问题\n",
    ")\n",
    "print(f\"创建文档分析: {doc_analysis.title} (ID: {doc_analysis.id})\")\n",
    "print(f\"初始状态: {doc_analysis.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 关联已有文件\n",
    "try:\n",
    "    doc_analysis.update_file_record(file_record)\n",
    "    print(f\"成功关联文件: {file_record.name}\")\n",
    "    #print(f\"提取的XML长度: {len(doc_analysis.raw_xml) if doc_analysis.raw_xml else 0}\")\n",
    "except Exception as e:\n",
    "    print(f\"关联文件失败: {str(e)}\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 提取元素\n",
    "extractor=DocxExtractor(doc_analysis)\n",
    "extractor.extract_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 打印元素\n",
    "from pprint import pprint\n",
    "Analysis1 = DocumentAnalysis.objects.get(id=doc_analysis.id)\n",
    "pprint(Analysis1.extracted_elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "场景2：创建分析并上传新文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#清除‘测试分析2”\n",
    "DocumentAnalysis.objects.filter(title=\"测试分析2\").delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 创建新的文档分析实例 - 测试分析2\n",
    "doc_analysis2 = DocumentAnalysis.objects.create(\n",
    "    project=project,\n",
    "    title=\"测试分析2\",\n",
    "    created_by=user,\n",
    "    analysis_questions=[\"投标要求\", \"评分标准\"]  # 示例分析问题\n",
    ")\n",
    "print(f\"创建文档分析: {doc_analysis2.title} (ID: {doc_analysis2.id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.上传真实的 DOCX文件\n",
    "\n",
    "# 2.1 准备文件路径\n",
    "doc_path = \"C:/Users/huiwa/Downloads/文本分析测试/CaseTest/case8：招标文件-第1包：一级压榨花生油.docx\"\n",
    "\n",
    "# 2.2 读取文件内容\n",
    "with open(doc_path, 'rb') as f:\n",
    "    file_content = f.read()\n",
    "test_file = SimpleUploadedFile(\n",
    "    \"test_doc.docx\",\n",
    "    file_content,\n",
    "    content_type=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
    ")\n",
    "print(f\"文件大小: {test_file.size}\")\n",
    "\n",
    "# 2. 创建新的文件记录 并 存储文件对象\n",
    "new_file_record = FileRecord.objects.create(\n",
    "    name=\"test_doc.docx\",\n",
    "    file=test_file,  # 使用之前准备的测试文件\n",
    "    owner=user,\n",
    "    size = test_file.size\n",
    ")\n",
    "print(f\"创建文件记录: {new_file_record.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 关联新文件\n",
    "try:\n",
    "    doc_analysis2.update_file_record(new_file_record)\n",
    "except Exception as e:\n",
    "    print(f\"关联文件失败: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 触发开始分析，并提取文档元素 elements 存入数据库\n",
    "print(\"\\n===== 最终状态检查 =====\")\n",
    "print(f\"开始分析前-状态: {doc_analysis2.status}\")\n",
    "doc_analysis2.start_analysis()\n",
    "print(f\"开始分析后-状态: {doc_analysis2.status}\")\n",
    "extractor2=DocxExtractor(doc_analysis2)\n",
    "extractor2.extract_elements();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange size=3> 文章结构分析 <font> <br>\n",
    "<font color=gray size=2> \n",
    "当我们分析招标文件时，首先会检视阅读，了解文档的框架和结构。<br>\n",
    "好的框架和结构，能让大模型更好地理解文档的上下文。 <br>\n",
    "具体到特定分析时，大模型能够根据框架结构，更准确地找到相关的内容。<br>\n",
    "\n",
    "这会带来两个好处：<br>\n",
    "1. 提升分析结果的准确性，避免无关内容带来的噪音影响<br>\n",
    "2. 减少大模型分析时使用的token数，降低成本。 <br>\n",
    "\n",
    "所以，我们会在这个环节，花一点时间和资源，来检视和校准文档的章节结构。<br>\n",
    "\n",
    "章节结构信息通常来自：<br>\n",
    "1. 文档开头的目录<br>\n",
    "2. 正文中的标题（H1,H2,H3）或文档大纲<br>\n",
    "\n",
    "理想情况下，它们的信息应该一致。如果不一致，就优先级而言，目录的优先级最高，其次是文档大纲，最后是标题。 <br>\n",
    "\n",
    "章节结构层级通常建议在2-3级，过高的层级会造成大模型在选择上下文时无所适从，而过多的层级则无法体现文档的结构化信息。这也是检视的重点。我们会结合章节的篇幅给予建议，并借助大模型来获得更多的章节信息。<br>\n",
    "\n",
    "最后，我们将向您交付章节结构的信息，您可以据此进行最终确认或进一步调整。 <br>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从数据库提取文档元素 elements 用于分析\n",
    "elements = doc_analysis2.extracted_elements\n",
    "from pprint import pprint\n",
    "pprint(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印文档目录\n",
    "print(\"====== 文档目录 ======\")\n",
    "for elem in elements:\n",
    "    if elem['is_toc'] == True:\n",
    "        print(f\"{elem['sequence_number']}  {elem['content'][:30]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印章节标题\n",
    "print(\"====== 文档大纲标题 ======\")\n",
    "for elem in elements:\n",
    "    if elem['is_heading'] == True:\n",
    "        print(f\"{elem['sequence_number']}  {elem['content'][:30]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入分析器，并进行大纲分析，返回分析结果results\n",
    "from apps.doc_analysis.outline_analyzer import DocumentOutlineAnalyzer\n",
    "OutlineAnalyzer = DocumentOutlineAnalyzer(elements)\n",
    "results = OutlineAnalyzer.compare_toc_and_outline()\n",
    "# 打印分析结果\n",
    "print(f\"目录但非大纲标题的元素: {len(results['toc_only'])}\")\n",
    "print(f\"大纲标题但非目录的元素: {len(results['outline_only'])}\")\n",
    "print(f\"大纲标题层级与目录标题层级不匹配元素:{len(results['level_differences'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成建议\n",
    "suggestions = OutlineAnalyzer.outline_suggestions(results)\n",
    "pprint(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#采纳建议\n",
    "# confirmed_suggestions 来自用户前端\n",
    "confirmed_suggestions = None\n",
    "OutlineAnalyzer.corrrect_outline(confirmed_suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutlineAnalyzer.print_analysis_results(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in elements:\n",
    "    if elem['element_type'] == 'ElementType.PARAGRAPH':\n",
    "        print(f\"{elem['sequence_number']}  {elem['content'][:30]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(elements[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.doc_analysis.docx_parser._03_element_extractor import ElementType, DocumentElement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_type = elements[0]['element_type']\n",
    "print(type(ele_type),ele_type)\n",
    "ele_sequence_number = elements[0]['sequence_number']\n",
    "print(type(ele_sequence_number), ele_sequence_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements[0]['element_type'] == 'ElementType.PARAGRAPH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.doc_analysis.doc_structurer._03_tree_builder import TreeBuilder\n",
    "from apps.doc_analysis.doc_structurer.doc_tree_retriever import DocTreeRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_builder = TreeBuilder(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_structure = tree_builder.build_to_level(target_level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>1. 测试分析模型 Models.py：创建和状态自动更新<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建文档分析\n",
    "analyses = DocumentAnalysis.objects.filter(project=project, file_record=file_record)\n",
    "isAnalysisExist = analyses.exists()\n",
    "if isAnalysisExist:\n",
    "    print(f\"分析已存在，跳过创建\")\n",
    "    this_analysis = analyses.filter(title=\"测试分析\")\n",
    "    this_analysis.update(status=DocumentAnalysis.AnalysisStatus.PENDING)\n",
    "    print(f\"初始化文档分析为PENDING状态: {this_analysis.first().status}\")\n",
    "\n",
    "else:\n",
    "    analysis = DocumentAnalysis.objects.create(\n",
    "        title=\"测试分析\",\n",
    "        project=project,\n",
    "        file_record=file_record,\n",
    "        created_by=user\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印分析列表\n",
    "analyses = DocumentAnalysis.objects.filter(title__startswith='测试分析')\n",
    "for analysis in analyses:\n",
    "    print(f\"分析号:{analysis.id}\\n\",\n",
    "          f\"分析名称：{analysis.title}\\n\",\n",
    "          f\"分析所在项目：{analysis.project.project_name}\\n\", \n",
    "          f\"分析的文件：{analysis.file_record.name}\\n\" ,\n",
    "          f\"分析的阶段：{analysis.status}\\n\",\n",
    "          f\"分析的问题：{analysis.analysis_questions}\\n\",\n",
    "          f\"分析结果：{analysis.analysis_result}\\n\",\n",
    "          f\"分析创建者：{analysis.created_by.phone}\\n\",\n",
    "          f\"分析用时：{analysis.processing_time}\\n\",\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试状态转换流程\n",
    "if analysis.status == DocumentAnalysis.AnalysisStatus.PENDING:\n",
    "    print(\"1.可以测试文档分析从PENDING到PROCESSING的流转：\")\n",
    "    analysis.start_analysis()\n",
    "    print(f\"开始分析后状态: {analysis.status}\")\n",
    "else:\n",
    "    print(f\"1. 测试文档分析状态在{analysis.status}，不能使用start_analysis()方法\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟分析结果\n",
    "sample_result = [\n",
    "    {\n",
    "        \"question\": \"资质要求\",\n",
    "        \"answer\": \"需要具备建筑施工总承包特级资质\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"技术参数\",\n",
    "        \"answer\": \"项目规模：建筑面积50000平方米\"\n",
    "    }\n",
    "]\n",
    "# 完成分析\n",
    "if analysis.status == DocumentAnalysis.AnalysisStatus.PROCESSING:\n",
    "    print(\"2.可以测试文档分析从PROCESSING到COMPLETED的流转：\")\n",
    "    analysis.complete_analysis(result=sample_result)\n",
    "    print(f\"完成分析后状态: {analysis.status}\")\n",
    "\n",
    "else:\n",
    "    print(f\"2. 测试文档分析状态在{analysis.status}，不能使用complete_analysis()方法\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确认分析结果\n",
    "confirmed_results = [\n",
    "    {\n",
    "        \"question\": \"资质要求\",\n",
    "        \"answer\": \"需要具备建筑施工总承包特级资质\",\n",
    "        \"comment\": \"确认无误\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"技术参数\",\n",
    "        \"answer\": \"项目规模：建筑面积50000平方米\",\n",
    "        \"comment\": \"数据已核实\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 完成分析\n",
    "if analysis.status == DocumentAnalysis.AnalysisStatus.COMPLETED:\n",
    "    print(\"3.可以测试文档分析从COMPLETED到CONFIRMED的流转：\")\n",
    "    analysis.confirm_analysis(user=user, confirmed_results=confirmed_results)\n",
    "    print(f\"完成分析后状态: {analysis.status}\")\n",
    "\n",
    "else:\n",
    "    print(f\"3. 测试文档分析状态在{analysis.status}，不能使用confirm_analysis()方法\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试错误状态转换\n",
    "print(\"\\n2. 测试错误状态转换处理：\")\n",
    "try:\n",
    "    # 创建新的分析实例用于测试失败场景\n",
    "    failed_analysis = DocumentAnalysis.objects.create(\n",
    "        title=\"测试失败分析\",\n",
    "        project=project,\n",
    "        file_record=file_record,\n",
    "        created_by=user\n",
    "    )\n",
    "    print(f\"创建失败分析的状态: {failed_analysis.status}\")\n",
    "    # 直接尝试确认一个未完成的分析\n",
    "    failed_analysis.confirm_analysis(user=user, confirmed_results=[])\n",
    "except InvalidStatusTransition as e:\n",
    "    print(f\"预期的错误捕获: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failed_analysis.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试失败流程\n",
    "failed_analysis.start_analysis()\n",
    "failed_analysis.fail_analysis(error_message=\"文档格式不支持\")\n",
    "print(f\"失败分析状态: {failed_analysis.status}\")\n",
    "print(f\"错误信息: {failed_analysis.error_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看分析结果\n",
    "print(\"\\n3. 查看最终分析结果：\")\n",
    "final_analysis = DocumentAnalysis.objects.get(id=analysis.id)\n",
    "print(f\"分析标题: {final_analysis.title}\")\n",
    "print(f\"当前状态: {final_analysis.status}\")\n",
    "print(f\"分析结果: {final_analysis.analysis_result}\")\n",
    "print(f\"确认时间: {final_analysis.confirmed_at}\")\n",
    "print(f\"确认用户: {final_analysis.confirmed_by.phone}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>2.Serializers.py测试<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.doc_analysis.serializers import ( \n",
    "    DocumentAnalysisBaseSerializer, \n",
    "    DocumentAnalysisCreateSerializer,\n",
    "    AnalysisResultUpdateSerializer,\n",
    "    AnalysisConfirmationSerializer,\n",
    "    DocumentAnalysisDisplaySerializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备测试数据\n",
    "test_file = FileRecord.objects.get(id='2')\n",
    "test_project = Project.objects.get(project_name='测试项目1')\n",
    "test_user = User.objects.get(phone='18501771516')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟请求类\n",
    "class MockRequest:\n",
    "    def __init__(self, user=None):\n",
    "        self.user = test_user\n",
    "        self.method = 'POST'  # 可以根据需要设置请求方法\n",
    "        self.META = {}        # 请求元数据\n",
    "        self.session = {}     # 会话数据\n",
    "\n",
    "# 创建模拟请求实例\n",
    "mock_request = MockRequest(user=test_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 测试创建序列化器\n",
    "print(\"=== 测试创建序列化器 ===\")\n",
    "create_data = {\n",
    "    \"project_id\": test_project.id,\n",
    "    \"file_record_id\": test_file.id,\n",
    "    \"title\": \"序列化器测试分析\",\n",
    "    \"analysis_questions\": [\"资质要求\", \"技术参数\"]\n",
    "}\n",
    "\n",
    "create_serializer = DocumentAnalysisCreateSerializer(\n",
    "    data=create_data,\n",
    "    context={'request': MockRequest()}\n",
    ")\n",
    "\n",
    "if create_serializer.is_valid():\n",
    "    new_analysis = create_serializer.save()\n",
    "    print(f\"✅ 创建成功 - ID: {new_analysis.id}\")\n",
    "else:\n",
    "    print(f\"❌ 创建失败 - 错误: {create_serializer.errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印new_analysis\n",
    "for analysis in [new_analysis]:\n",
    "    print(f\"分析号:{analysis.id}\\n\",\n",
    "          f\"分析名称：{analysis.title}\\n\",\n",
    "          f\"分析所在项目：{analysis.project.project_name}\\n\", \n",
    "          f\"分析的文件：{analysis.file_record.name}\\n\" ,\n",
    "          f\"分析的阶段：{analysis.status}\\n\",\n",
    "          f\"分析的问题：{analysis.analysis_questions}\\n\",\n",
    "          f\"分析结果：{analysis.analysis_result}\\n\",\n",
    "          f\"分析创建者：{analysis.created_by.phone}\\n\",\n",
    "          f\"分析用时：{analysis.processing_time}\\n\",\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试无效文件类型\n",
    "print(\"\\n测试无效文件类型:\")\n",
    "invalid_file = FileRecord.objects.create(\n",
    "    name=\"test.txt\",\n",
    "    type=\"TXT\",\n",
    "    size=1024,\n",
    "    owner=test_user,  # 添加必需的owner字段\n",
    "    version=1,        # 添加必需的version字段\n",
    "    processing_status='NONE',  # 添加必需的processing_status字段\n",
    "    created_by=test_user.phone  # 添加必需的created_by字段\n",
    ")\n",
    "\n",
    "invalid_data = create_data.copy()\n",
    "invalid_data[\"file_record_id\"] = invalid_file.id\n",
    "\n",
    "invalid_serializer = DocumentAnalysisCreateSerializer(\n",
    "    data=invalid_data,\n",
    "    context={'request': mock_request}\n",
    ")\n",
    "\n",
    "if not invalid_serializer.is_valid():\n",
    "    print(f\"✅ 正确捕获错误: {invalid_serializer.errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 测试结果更新序列化器\n",
    "print(\"\\n=== 测试结果更新序列化器 ===\")\n",
    "update_data = {\n",
    "\n",
    "            \"question\": \"资质要求\",\n",
    "            \"answer\": \"需要具备建筑施工总承包特级资质\",\n",
    "            \"context\": [\"上下文段落1\", \"上下文段落2\"],\n",
    "            \"confidence\": 0.95\n",
    "        }\n",
    "\n",
    "result_serializer = AnalysisResultUpdateSerializer(\n",
    "    instance=new_analysis,\n",
    "    data=update_data,\n",
    "    context={'request': mock_request}\n",
    ")\n",
    "\n",
    "if result_serializer.is_valid():\n",
    "    updated = result_serializer.save()\n",
    "    print(f\"✅ 结果更新成功 - 最新结果: {updated.analysis_result[-1]}\")\n",
    "else:\n",
    "    print(f\"❌ 更新失败 - 错误: {result_serializer.errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 测试确认序列化器\n",
    "print(\"\\n=== 测试确认序列化器 ===\")\n",
    "confirmation_data = {\n",
    "            \"question\": \"资质要求\",\n",
    "            \"answer\": \"需要具备建筑施工总承包特级资质\",\n",
    "            \"comment\": \"测试确认\"\n",
    "        }\n",
    "\n",
    "\n",
    "confirmation_serializer = AnalysisConfirmationSerializer(\n",
    "    instance=new_analysis,\n",
    "    data=confirmation_data,\n",
    "    context={'request': mock_request}\n",
    ")\n",
    "\n",
    "if confirmation_serializer.is_valid():\n",
    "    confirmed = confirmation_serializer.save()\n",
    "    print(f\"✅ 确认成功 - 状态: {confirmed.status}\")\n",
    "    print(f\"确认信息: {confirmed.analysis_result[0].get('confirmation')}\")\n",
    "else:\n",
    "    print(f\"❌ 确认失败 - 错误: {confirmation_serializer.errors}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BidPilot_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
