{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化\n",
    "import django_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.projects.models import Project, Task, TaskStatus, TaskType\n",
    "from typing import List\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟celery task 处获取 项目信息\n",
    "current_project = Project.objects.get(project_name='测试项目1')\n",
    "print(f\"用于测试的项目: {current_project.project_name}\")\n",
    "print(f\"项目包含的文件: {current_project.files.all()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.projects.services._02_outline_analysis import DocxOutlineAnalyzerStep\n",
    "outline_analysis_step = DocxOutlineAnalyzerStep()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline_analysis_step.process(current_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task.objects.get(stage__project=current_project, type=TaskType.DOCX_EXTRACTION_TASK)\n",
    "print(task.result_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模拟_02_outline_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate_input 处获取 项目信息\n",
    "def validate_input(data: Project) -> bool:\n",
    "    \"\"\"验证输入数据\"\"\"\n",
    "\n",
    "    # 检查是否存在DOCX_EXTRACTION_TASK类型的任务\n",
    "    task = Task.objects.get(stage__project=current_project, type=TaskType.DOCX_EXTRACTION_TASK)\n",
    "    if not task or not task.docx_tiptap:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "print(validate_input(current_project))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task.objects.get(stage__project=current_project, type=TaskType.DOCX_EXTRACTION_TASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(task.docx_tiptap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"计算文本的token数量\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    return len(encoding.encode(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------- prepare requests data -------\n",
    "# 测试helpers\n",
    "from apps.projects.tiptap.helpers import TiptapUtils\n",
    "paragraphs, index_path_map = TiptapUtils.extract_indexed_paragraphs(task.docx_tiptap, 50)\n",
    "print(count_tokens(str(paragraphs)))\n",
    "print(paragraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(index_path_map), type(paragraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_format_required() -> str:\n",
    "    \"\"\"\n",
    "    OutlineAnalysis会按chapter,section,subsection逐个层级比较<目录标题列表> 与 <正文标题列表>\n",
    "    以下定义了，大模型返回的输出格式的规范说明\n",
    "    \"\"\"\n",
    "    return \"\"\"\n",
    "\n",
    "生成 Markdown：\n",
    "标题使用相应级别的 Markdown 语法（#）\n",
    "保留 index 信息，使用 <!-- index: xxx --> 注释格式\n",
    "\n",
    "输入示例： \n",
    "\n",
    "[\n",
    "  {\"content\": \"第六章 投标文件格式\", \"index\": 484},\n",
    "  {\"content\": \"6.1 评标方法\", \"index\": 512},\n",
    "  {\"content\": \"6.1.1 资格审查\", \"index\": 530},\n",
    "  {\"content\": \"本项目采用综合评分法\", \"index\": 540}\n",
    "]\n",
    "\n",
    "\n",
    "输出示例：\n",
    "\n",
    "<!-- index: 484 -->\n",
    "# 第六章 投标文件格式\n",
    "\n",
    "<!-- index: 512 -->\n",
    "## 6.1 评标方法\n",
    "\n",
    "<!-- index: 530 -->\n",
    "### 6.1.1 资格审查\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_template() -> str:\n",
    "    return \"\"\"\n",
    "你是一个擅长文档结构分析的 AI，接下来我会提供一些文本内容，每条数据包含 content（文本内容）和 index（索引）。你的任务是：\n",
    "识别标题：判断文本是否是一个章节标题（例如“第X章”、“X.X”、“X.X.X” 等， 也可能是其他格式）。\n",
    "确定层级：\n",
    "“第X章” → H1（#）\n",
    "“X.X” → H2（##）\n",
    "“X.X.X” → H3（###）\n",
    "如果不是标题，则忽略\n",
    "\n",
    "\n",
    "\n",
    "## Format\n",
    "{output_format}\n",
    "\n",
    "# Input\n",
    "{data_input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps._tools.LLM_services._llm_data_types import LLMConfig\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_llm_config(model_name: str) -> LLMConfig:\n",
    "    \"\"\"构建LLM配置\"\"\"\n",
    "    return LLMConfig(\n",
    "                llm_model_name = model_name,  # qwen-plus\n",
    "                temperature = 0.7,\n",
    "                top_p =  0.8,\n",
    "                streaming = True,\n",
    "                api_key = os.getenv(\"ALIBABA_API_KEY\"),\n",
    "                base_url = \"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "                max_workers = 4,\n",
    "                timeout = 30,\n",
    "                retry_times = 3\n",
    "            )\n",
    "\n",
    "llm_config = build_llm_config(model_name=\"qwen-max-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_to_model = llm_config.to_model()\n",
    "print(type(llm_config_to_model))\n",
    "print(llm_config_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_from_model = LLMConfig.from_model(llm_config_to_model)\n",
    "print(type(llm_config_from_model))\n",
    "print(llm_config_from_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM CONFIG\n",
    "import os, asyncio, nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from apps._tools.LLM_services._llm_data_types import BatchResult, LLMConfig\n",
    "from apps._tools.LLM_services.llm_service import LLMService\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "def build_llm_config(model_name: str) -> LLMConfig:\n",
    "    \"\"\"构建LLM配置\"\"\"\n",
    "    return LLMConfig(\n",
    "                llm_model_name = model_name,  # qwen-plus\n",
    "                temperature = 0.7,\n",
    "                top_p =  0.8,\n",
    "                streaming = True,\n",
    "                api_key = os.getenv(\"ALIBABA_API_KEY\"),\n",
    "                base_url = \"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "                max_workers = 4,\n",
    "                timeout = 30,\n",
    "                retry_times = 3\n",
    "            )\n",
    "\n",
    "def llm_analyze(data_inputs: List[str], repeats: int = 1):\n",
    "    # 构建LLM服务所需配置\n",
    "    llm_config = build_llm_config(model_name=\"qwen-max-0125\")\n",
    "    prompt_template = build_prompt_template()\n",
    "    output_format = output_format_required()\n",
    "    \n",
    "    # 初始化LLM服务\n",
    "    llm_service = LLMService(\n",
    "        config=llm_config,\n",
    "        prompt_template=prompt_template,\n",
    "        output_format=output_format\n",
    "    )\n",
    "\n",
    "    # 异步分析封装\n",
    "    async def _analyze():\n",
    "        return await llm_service.analyze(\n",
    "            data_input=data_inputs,\n",
    "        )\n",
    "    \n",
    "    return asyncio.run(_analyze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inputs = paragraphs\n",
    "\n",
    "\n",
    "raw_results = llm_analyze(\n",
    "    data_inputs=data_inputs\n",
    ")\n",
    "print(raw_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(raw_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from apps.projects.tiptap.client import TiptapClient\n",
    "# client = TiptapClient()   \n",
    "# md = client.json_to_markdown(findings)\n",
    "# pprint(md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_requests_data 处获取 项目信息\n",
    "\n",
    "# def prepare_requests_data(data) -> List[str]:\n",
    "#     \"\"\"\n",
    "#     准备大模型分析所需的数据 data_inputs, 通常是List[str] 格式\n",
    "#     \"\"\"\n",
    "\n",
    "#     # 1. 提取目录标题列表\n",
    "#     toc_chapters = data.format_toc_chapters()\n",
    "#     toc_sections = data.format_toc_sections()#[:118]\n",
    "#     toc_subsections = data.format_toc_subsections()\n",
    "\n",
    "#     # 2. 提取正文标题列表\n",
    "#     heading_chapters = data.format_heading_chapters()\n",
    "#     heading_sections = data.format_heading_sections()#[:120]\n",
    "#     heading_subsections = data.format_heading_subsections()\n",
    "\n",
    "#     # 3. 构建数据输入\n",
    "#     data_input1 = self._build_data_input(toc_chapters, heading_chapters)\n",
    "#     data_input2 = self._build_data_input(toc_sections, heading_sections)\n",
    "#     data_input3 = self._build_data_input(toc_subsections, heading_subsections)\n",
    "\n",
    "#     data_inputs = [data_input1, data_input2, data_input3]\n",
    "\n",
    "#     return data_inputs\n",
    "\n",
    "# data_inputs = prepare_requests_data(current_project)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BidPilot_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
